{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1183165,"sourceType":"datasetVersion","datasetId":672377}],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nlist = []\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        list.append(os.path.join(dirname, filename))\n\n# Printing only the first 5 items in the list        \nfor i in range (5):\n    print(list[i])\n\nprint(\"...\")\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-30T12:26:18.284349Z","iopub.execute_input":"2024-09-30T12:26:18.285211Z","iopub.status.idle":"2024-09-30T12:26:20.081762Z","shell.execute_reply.started":"2024-09-30T12:26:18.285169Z","shell.execute_reply":"2024-09-30T12:26:20.080646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Project Setup and Initial File Exploration\n\nIn this cell, we begin by importing essential libraries such as:\n- `NumPy` for linear algebra operations.\n- `Pandas` for data processing and file input/output.\n\nThe code then explores the directory structure using the `os` library to locate and list all input files available in the read-only `/kaggle/input/` directory. The first five file paths are printed as a preview to understand the dataset structure. This step is critical for understanding the available data before performing any operations on it.\n\nAdditionally, it reminds the user about Kaggle's working directory limits and temporary storage.\n\n---","metadata":{}},{"cell_type":"code","source":"import keras\nfrom keras.layers import Conv2D, Flatten, Dense, Dropout, MaxPooling2D\nfrom keras.models import Sequential\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.utils import shuffle\n\nfrom PIL import Image\n\nimport cv2\nimport tqdm\nimport io\nimport ipywidgets as widgets\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2024-09-30T12:26:33.153776Z","iopub.execute_input":"2024-09-30T12:26:33.154267Z","iopub.status.idle":"2024-09-30T12:26:46.089263Z","shell.execute_reply.started":"2024-09-30T12:26:33.154228Z","shell.execute_reply":"2024-09-30T12:26:46.088494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Importing Essential Libraries for Model Development\n\nIn this cell, various libraries are imported to facilitate the construction and evaluation of the neural network model:\n\n- `Keras`: A high-level neural networks API, particularly for defining the convolutional layers (`Conv2D`), pooling (`MaxPooling2D`), dense layers, and dropout regularization.\n- `Sequential`: A model type in Keras used for building models layer by layer.\n- `Scikit-learn`: Libraries such as `train_test_split`, `accuracy_score`, and `shuffle` to help with data preprocessing, splitting, and evaluation.\n- `PIL (Python Imaging Library)` and `OpenCV (cv2)`: For image processing tasks.\n- `tqdm`: To display progress bars in loops.\n- `TensorFlow`: The backend library that powers Keras.\n\nThese imports are fundamental for building the convolutional neural network (CNN) model and for processing and splitting the image data.\n\n---\n","metadata":{}},{"cell_type":"code","source":"image_res = 150\n\nX_train = []\ny_train = []\n\nlabels = [\"glioma_tumor\", 'meningioma_tumor', 'no_tumor', \"pituitary_tumor\"]\n\nfor i in labels:\n    folder = os.path.join(\"/kaggle/input/brain-tumor-classification-mri/Training\", i)\n    \n    for j in os.listdir(folder):\n        image = cv2.imread(os.path.join(folder, j))\n        image = cv2.resize(image, (image_res, image_res))\n        X_train.append(image)\n        y_train.append(i)\n        \nfor i in labels:\n    folder = os.path.join(\"/kaggle/input/brain-tumor-classification-mri/Testing\", i)\n    \n    for j in os.listdir(folder):\n        image = cv2.imread(os.path.join(folder, j))\n        image = cv2.resize(image, (image_res, image_res))\n        X_train.append(image)\n        y_train.append(i)\n        \nX_train = np.array(X_train)\ny_train = np.array(y_train)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T12:31:32.322292Z","iopub.execute_input":"2024-09-30T12:31:32.322989Z","iopub.status.idle":"2024-09-30T12:31:39.220676Z","shell.execute_reply.started":"2024-09-30T12:31:32.322948Z","shell.execute_reply":"2024-09-30T12:31:39.219652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loading and Preprocessing the Image Data\n\nThis cell handles the loading, resizing, and organizing of MRI images into training data for the model:\n\n- The image resolution is set to `150x150` (`image_res = 150`).\n- Two lists, `X_train` (for images) and `y_train` (for labels), are initialized to store the processed data.\n- The `labels` array contains the four types of tumors: `\"glioma_tumor\"`, `\"meningioma_tumor\"`, `\"no_tumor\"`, and `\"pituitary_tumor\"`.\n\nFor both the training and testing datasets, the code:\n1. Loads images from the respective directories (`Training` and `Testing`) for each tumor category.\n2. Uses OpenCV (`cv2.imread`) to read the images and resizes them to `150x150` pixels (`cv2.resize`).\n3. Appends the resized images to `X_train` and their corresponding labels to `y_train`.\n\nFinally, both `X_train` and `y_train` are converted to NumPy arrays for efficient manipulation in the model.\n\nThis step prepares the image data for further processing and model training.\n\n---\n","metadata":{}},{"cell_type":"code","source":"X_train, y_train = shuffle(X_train, y_train, random_state = 42)\nX_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-30T12:31:42.252559Z","iopub.execute_input":"2024-09-30T12:31:42.253396Z","iopub.status.idle":"2024-09-30T12:31:42.325837Z","shell.execute_reply.started":"2024-09-30T12:31:42.253356Z","shell.execute_reply":"2024-09-30T12:31:42.324941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Shuffling the Dataset and Checking the Shape\n\nIn this cell, the training data (`X_train` and `y_train`) is shuffled to ensure that the order of the images is randomized. This is important because shuffling helps prevent the model from learning patterns based on the order in which data is presented during training.\n\n- The `shuffle` function from `sklearn.utils` is used, with a `random_state` of `42` to ensure reproducibility.\n- The shape of `X_train` is displayed to verify the dimensions of the image data after shuffling. This step helps confirm that the dataset is prepared and organized correctly before feeding it into the model.\n\n---\n","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1,random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T12:31:44.936931Z","iopub.execute_input":"2024-09-30T12:31:44.938006Z","iopub.status.idle":"2024-09-30T12:31:45.003914Z","shell.execute_reply.started":"2024-09-30T12:31:44.937947Z","shell.execute_reply":"2024-09-30T12:31:45.003085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Splitting the Dataset into Training and Testing Sets\n\nHere, the `train_test_split` function from `sklearn.model_selection` is used to divide the shuffled data into training and testing subsets:\n- `X_train` and `y_train` contain the majority of the data, while `X_test` and `y_test` hold a smaller portion for validation.\n- The `test_size=0.1` parameter means that 10% of the data is reserved for testing, ensuring that the model's performance can be evaluated on unseen data.\n- The `random_state=42` ensures that the split is reproducible.\n\nThis step is essential for evaluating the generalization ability of the model by separating a portion of the data that the model won't see during training.\n\n---","metadata":{}},{"cell_type":"code","source":"y_train_new = []\n\nfor i in y_train:\n    y_train_new.append(labels.index(i))\ny_train=y_train_new\ny_train = tf.keras.utils.to_categorical(y_train)\n\n\ny_test_new = []\n\nfor i in y_test:\n    y_test_new.append(labels.index(i))\ny_test=y_test_new\ny_test = tf.keras.utils.to_categorical(y_test)\n# ????","metadata":{"execution":{"iopub.status.busy":"2024-09-30T12:42:51.390241Z","iopub.execute_input":"2024-09-30T12:42:51.390894Z","iopub.status.idle":"2024-09-30T12:42:51.442933Z","shell.execute_reply.started":"2024-09-30T12:42:51.390853Z","shell.execute_reply":"2024-09-30T12:42:51.441707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encoding the Labels and One-Hot Encoding\n\nThis cell handles the conversion of the tumor type labels into numerical format and then applies one-hot encoding, which is crucial for categorical classification tasks:\n\n1. **Label Conversion**: \n   - The `labels.index(i)` function is used to convert each label in `y_train` and `y_test` into an integer (e.g., \"glioma_tumor\" becomes 0, \"meningioma_tumor\" becomes 1, etc.).\n   - This step is required because machine learning models work with numerical data, not strings.\n\n2. **One-Hot Encoding**:\n   - After converting the labels into integers, `tf.keras.utils.to_categorical` is applied to transform these integers into one-hot encoded vectors.\n   - One-hot encoding is essential in multi-class classification problems as it converts each label into a binary vector of length equal to the number of classes (in this case, 4 classes).\n\nThe result is that `y_train` and `y_test` are transformed into matrices where each row is a one-hot encoded representation of the original label.\n\n---","metadata":{}},{"cell_type":"code","source":"model = Sequential()\n\n# 1st block\nmodel.add(Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)))\nmodel.add(Conv2D(32, (3,3), activation='relu'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.2))\n\n# 2nd block\nmodel.add(Conv2D(64, (3,3), activation='relu'))\nmodel.add(Conv2D(64, (3,3), activation='relu'))\nmodel.add(MaxPooling2D(2,2))\n\n# 3rd block\nmodel.add(Conv2D(128, (3,3), activation='relu'))\nmodel.add(Conv2D(128, (3,3), activation='relu'))\nmodel.add(MaxPooling2D(2,2))\n\n# 4th block\nmodel.add(Conv2D(256, (3,3), activation='relu'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Dropout(0.3))\n\n# Fully connected layers\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\n\n# Output layer (for multi-class classification)\nmodel.add(Dense(4, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2024-09-30T12:32:15.452061Z","iopub.execute_input":"2024-09-30T12:32:15.452795Z","iopub.status.idle":"2024-09-30T12:32:16.340955Z","shell.execute_reply.started":"2024-09-30T12:32:15.452757Z","shell.execute_reply":"2024-09-30T12:32:16.339920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Building the Convolutional Neural Network (CNN) Model\n\nIn this cell, a deep Convolutional Neural Network (CNN) is constructed using the `Sequential` model from Keras. The architecture consists of several convolutional blocks followed by fully connected layers:\n\n1. **1st Block**:\n   - Two convolutional layers with 32 filters, each using a 3x3 kernel, and ReLU activation.\n   - Followed by a Max Pooling layer to downsample the spatial dimensions and a Dropout layer (0.2) to prevent overfitting.\n\n2. **2nd Block**:\n   - Two convolutional layers with 64 filters, again with 3x3 kernels and ReLU activation.\n   - Followed by a Max Pooling layer for further downsampling.\n\n3. **3rd Block**:\n   - Two convolutional layers with 128 filters and ReLU activation, followed by Max Pooling.\n\n4. **4th Block**:\n   - One convolutional layer with 256 filters and ReLU activation.\n   - Followed by Max Pooling and a stronger Dropout (0.3) to further reduce overfitting.\n\n5. **Fully Connected Layers**:\n   - After flattening the feature maps, a dense layer with 512 units and ReLU activation is added.\n   - A Dropout layer (0.5) is applied for regularization.\n   - Another dense layer with 256 units and ReLU activation is added, followed by a Dropout (0.5).\n   \n6. **Output Layer**:\n   - The final dense layer has 4 units (corresponding to the 4 tumor categories) and uses the `softmax` activation function, which is suited for multi-class classification.\n\nThis CNN architecture is designed to progressively extract high-level features from the images while incorporating dropout layers to mitigate overfitting. \n\n---","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-09-30T12:34:30.223542Z","iopub.execute_input":"2024-09-30T12:34:30.224392Z","iopub.status.idle":"2024-09-30T12:34:30.260180Z","shell.execute_reply.started":"2024-09-30T12:34:30.224352Z","shell.execute_reply":"2024-09-30T12:34:30.259352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Summary\n\nThe `model.summary()` function prints a detailed summary of the CNN model architecture, showing:\n- The layer-by-layer breakdown, including the type of layers (Conv2D, MaxPooling2D, Dense, etc.).\n- The number of parameters for each layer (trainable parameters such as weights and biases).\n- The output shape after each layer, providing a clear understanding of how the input image is transformed as it passes through the network.\n\n---","metadata":{}},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-09-30T12:34:44.819866Z","iopub.execute_input":"2024-09-30T12:34:44.820236Z","iopub.status.idle":"2024-09-30T12:34:44.829305Z","shell.execute_reply.started":"2024-09-30T12:34:44.820200Z","shell.execute_reply":"2024-09-30T12:34:44.828491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Compiling the Model\n\nIn this cell, the model is compiled using the following parameters:\n\n- **Loss Function**: \n  - `categorical_crossentropy` is chosen as the loss function, which is suitable for multi-class classification problems where the output is one-hot encoded. It measures the dissimilarity between the predicted and true label distributions.\n\n- **Optimizer**: \n  - `Adam` optimizer is used for training the model. Adam is popular due to its adaptive learning rate capabilities, which often leads to faster convergence.\n\n- **Metrics**: \n  - The model will track `accuracy` as a performance metric during training and evaluation, providing a straightforward indication of the model's predictive performance on the dataset.\n\nCompiling the model is a critical step before training, as it sets the optimization strategy and evaluation criteria.\n\n---","metadata":{}},{"cell_type":"code","source":"history = model.fit(X_train, y_train, epochs = 30, validation_split = 0.1)","metadata":{"execution":{"iopub.status.busy":"2024-09-30T12:35:36.439725Z","iopub.execute_input":"2024-09-30T12:35:36.440109Z","iopub.status.idle":"2024-09-30T12:37:01.133401Z","shell.execute_reply.started":"2024-09-30T12:35:36.440072Z","shell.execute_reply":"2024-09-30T12:37:01.132631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training the Model\n\nIn this cell, the model is trained using the `fit` method with the following parameters:\n\n- **Training Data**: \n  - `X_train` (input images) and `y_train` (one-hot encoded labels) are used for training the model.\n\n- **Epochs**: \n  - The model will be trained for 30 epochs, meaning the entire training dataset will be passed through the model 30 times. This allows the model to learn from the data iteratively.\n\n- **Validation Split**: \n  - A validation split of 0.1 indicates that 10% of the training data will be reserved for validation. This means the model's performance will be evaluated on this subset at the end of each epoch, helping to monitor overfitting.\n\nThe `history` variable will store the training process details, including the loss and accuracy metrics for both training and validation sets over the epochs. This information is crucial for analyzing the model's performance and making necessary adjustments.\n\n---","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2024-09-30T12:37:23.459603Z","iopub.execute_input":"2024-09-30T12:37:23.459997Z","iopub.status.idle":"2024-09-30T12:37:23.680238Z","shell.execute_reply.started":"2024-09-30T12:37:23.459961Z","shell.execute_reply":"2024-09-30T12:37:23.679230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = history.history[\"accuracy\"]\nvalidation_accuracy = history.history[\"val_accuracy\"]\n\nepochs = range(len(accuracy))\n\nfig = plt.figure(figsize = (14, 7))\nplt.plot(epochs, accuracy, \"r\", label = \"Accuracy of Training\")\nplt.plot(epochs, validation_accuracy, \"b\", label = \"Accuracy of Validation Accuracy\")\nplt.legend(loc = 'upper left')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-30T12:37:25.726020Z","iopub.execute_input":"2024-09-30T12:37:25.727013Z","iopub.status.idle":"2024-09-30T12:37:26.038584Z","shell.execute_reply.started":"2024-09-30T12:37:25.726972Z","shell.execute_reply":"2024-09-30T12:37:26.037644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing Model Accuracy\n\nIn this cell, the training and validation accuracy of the model are visualized using a line plot. The following steps are performed:\n\n- **Extracting Accuracy Data**:\n  - The accuracy of the training set is obtained from `history.history[\"accuracy\"]`.\n  - The validation accuracy is obtained from `history.history[\"val_accuracy\"]`.\n\n- **Creating Epochs Range**:\n  - A range of epochs is generated to correspond with the accuracy values.\n\n- **Plotting**:\n  - A figure is created with a size of 14x7 inches.\n  - The training accuracy is plotted in red, while the validation accuracy is plotted in blue.\n  - A legend is included to distinguish between the training and validation accuracy curves.\n\nThis visualization is essential for understanding how well the model learned during training and how it performs on unseen data. It can help identify issues such as overfitting or underfitting, guiding further model improvements.\n\n---","metadata":{}},{"cell_type":"code","source":"loss = history.history[\"loss\"]\nvalidation_loss = history.history[\"val_loss\"]\n\nepochs = range(len(loss))\n\nfig = plt.figure(figsize = (14, 7))\nplt.plot(epochs, loss, \"r\", label = \"Loss of Training\")\nplt.plot(epochs, validation_loss, \"b\", label = \"Loss of Validation Accuracy\")\nplt.legend(loc = 'upper left')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-30T12:38:11.042653Z","iopub.execute_input":"2024-09-30T12:38:11.043052Z","iopub.status.idle":"2024-09-30T12:38:11.346321Z","shell.execute_reply.started":"2024-09-30T12:38:11.043013Z","shell.execute_reply":"2024-09-30T12:38:11.345428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing Model Loss\n\nIn this cell, the training and validation loss of the model are visualized using a line plot. The following steps are carried out:\n\n- **Extracting Loss Data**:\n  - The training loss is retrieved from `history.history[\"loss\"]`.\n  - The validation loss is retrieved from `history.history[\"val_loss\"]`.\n\n- **Creating Epochs Range**:\n  - A range of epochs is generated to align with the loss values.\n\n- **Plotting**:\n  - A figure is created with a size of 14x7 inches.\n  - The training loss is plotted in red, while the validation loss is plotted in blue.\n  - A legend is included to differentiate between the training and validation loss curves.\n\nThis visualization is crucial for assessing the model's performance during training. A decreasing trend in both training and validation loss indicates that the model is learning effectively. If the validation loss begins to rise while the training loss continues to decrease, this could signal overfitting, suggesting that further adjustments may be needed.\n\n---","metadata":{}},{"cell_type":"code","source":"image = cv2.imread('/kaggle/input/brain-tumor-classification-mri/Training/pituitary_tumor/p (112).jpg')\nimage = cv2.resize(image, (150, 150))\nimage_array = np.array(image)\nimage_array.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-30T12:39:09.628631Z","iopub.execute_input":"2024-09-30T12:39:09.629000Z","iopub.status.idle":"2024-09-30T12:39:09.647017Z","shell.execute_reply.started":"2024-09-30T12:39:09.628966Z","shell.execute_reply":"2024-09-30T12:39:09.646138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loading and Preprocessing a Sample Image\n\nIn this cell, a sample image from the training dataset is loaded and preprocessed for evaluation. The following steps are performed:\n\n- **Image Loading**:\n  - The image is read from the specified file path using `cv2.imread()`.\n\n- **Image Resizing**:\n  - The image is resized to 150x150 pixels using `cv2.resize()`. This is necessary to ensure the image dimensions match the input shape expected by the model.\n\n- **Converting to Array**:\n  - The resized image is converted to a NumPy array using `np.array()`. This conversion allows the image data to be used as input for the model.\n\n- **Displaying Shape**:\n  - The shape of the resulting image array is displayed. This shape will indicate the dimensions and number of color channels in the image (e.g., `(150, 150, 3)` for a 150x150 RGB image).\n\n---","metadata":{}},{"cell_type":"code","source":"image_array = image_array.reshape(1, 150, 150, 3)\nimage_array.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-30T12:39:29.983005Z","iopub.execute_input":"2024-09-30T12:39:29.983358Z","iopub.status.idle":"2024-09-30T12:39:29.989844Z","shell.execute_reply.started":"2024-09-30T12:39:29.983325Z","shell.execute_reply":"2024-09-30T12:39:29.988865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reshaping the Image Array for Model Input\n\nIn this cell, the shape of the previously prepared image array is modified to make it suitable for input into the model. The following steps are performed:\n\n- **Reshaping the Array**:\n  - The image array, originally with the shape `(150, 150, 3)`, is reshaped using `reshape(1, 150, 150, 3)`. This adds a new dimension at the beginning, transforming the array into the shape `(1, 150, 150, 3)`.\n  - The new shape indicates that the array now contains one image with dimensions 150x150 pixels and 3 color channels (RGB).\n\nThis reshaping step is essential because the model expects input data to be in batches, even if there is only a single image. It ensures compatibility with the model's input layer, allowing the model to process the image correctly for prediction.\n\n---","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\nimg = image.load_img('/kaggle/input/brain-tumor-classification-mri/Training/glioma_tumor/gg (107).jpg')\nplt.imshow(img,interpolation='nearest')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-30T12:44:12.422729Z","iopub.execute_input":"2024-09-30T12:44:12.423668Z","iopub.status.idle":"2024-09-30T12:44:12.624771Z","shell.execute_reply.started":"2024-09-30T12:44:12.423609Z","shell.execute_reply":"2024-09-30T12:44:12.623898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing a Sample Image from the Dataset\n\nIn this cell, a sample image from the training dataset is loaded and displayed. The following steps are performed:\n\n- **Image Loading**:\n  - The image is loaded using `image.load_img()` from TensorFlow's Keras preprocessing module. This function allows for loading images directly from file paths while automatically handling different formats.\n\n- **Displaying the Image**:\n  - The loaded image is displayed using `plt.imshow()`, with the `interpolation` parameter set to 'nearest' to control the rendering of the image.\n  - `plt.show()` is called to render the image in the output cell.\n\nThis visualization step helps in understanding the type of data being used for model training. By inspecting sample images, one can gain insights into the quality and characteristics of the dataset, which is important for evaluating the model's potential performance.\n\n---","metadata":{}},{"cell_type":"code","source":"pre = model.predict(image_array)\nindices = pre.argmax()\nindices","metadata":{"execution":{"iopub.status.busy":"2024-09-30T12:44:14.387996Z","iopub.execute_input":"2024-09-30T12:44:14.388785Z","iopub.status.idle":"2024-09-30T12:44:14.455204Z","shell.execute_reply.started":"2024-09-30T12:44:14.388741Z","shell.execute_reply":"2024-09-30T12:44:14.454337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Making Predictions with the Model\n\nIn this cell, the model is used to make predictions on the preprocessed image. The following steps are performed:\n\n- **Model Prediction**:\n  - The model's `predict()` method is called with the reshaped `image_array` as input. This method generates predictions for the class of the tumor represented in the image.\n\n- **Determining the Class Index**:\n  - The predictions are processed using `argmax()` to find the index of the class with the highest predicted probability. This index corresponds to the predicted class label.\n\n- **Displaying the Class Index**:\n  - The resulting index (`indices`) is displayed. This index can be mapped back to the corresponding tumor type using the predefined `labels` list.\n\n---","metadata":{}},{"cell_type":"markdown","source":"### Brain Tumor Classification Project Overview\n\nThis project aims to develop a machine learning model for the classification of brain tumor types using MRI images. The primary goal is to accurately predict tumor types, specifically glioma, meningioma, pituitary, and no tumor. Below is an overview of the key steps undertaken in this project:\n\n1. **Library Imports**:\n   - Essential libraries such as TensorFlow, Keras, OpenCV, and others are imported to facilitate data processing, model building, and image handling.\n\n2. **Data Exploration**:\n   - The dataset is explored by listing the available files and their structure. This helps understand the data organization and the number of images for each tumor type.\n\n3. **Data Preparation**:\n   - MRI images are read and resized to a uniform dimension of 150x150 pixels. Labels corresponding to each image are created to prepare for supervised learning.\n   - The training dataset is shuffled to ensure randomness and split into training and testing sets for model validation.\n\n4. **Label Encoding**:\n   - The categorical labels are converted into a numerical format, and one-hot encoding is applied to prepare the labels for model training.\n\n5. **Model Architecture**:\n   - A Convolutional Neural Network (CNN) is built using Keras with multiple convolutional layers, pooling layers, and dropout layers to enhance feature extraction and reduce overfitting.\n\n6. **Model Compilation and Training**:\n   - The model is compiled with categorical cross-entropy loss and the Adam optimizer. It is then trained for 30 epochs with a portion of the data reserved for validation.\n\n7. **Performance Evaluation**:\n   - The training and validation accuracy and loss are plotted to visualize the model's performance and convergence behavior over the epochs.\n\n8. **Predictions**:\n   - Finally, the model is used to make predictions on new images, determining the predicted tumor type based on the trained model.\n\nThis project illustrates the end-to-end process of building a deep learning model for image classification, focusing on medical applications in brain tumor diagnosis.\n\n---","metadata":{}}]}